# Usage::
#   CONFIG_NAME=dev.yaml uvicorn backend.main:app --host 0.0.0.0 --port 8101 --reload --reload-dir ./backend
#   streamlit run run_flowagent_ui2.py --server.port 8502 -- --config=dev.yaml --page_default_index=0
defaults: !include default.yaml

x-available-models: &available_models
  - "1.0.2"
  - "default"
  - "test-eason"
  - "debug"
  - "gpt-4o-mini"
  - "gpt-4o"
  - "gpt-4-turbo"
  - claude-3-5-sonnet-20241022
  - Vendor-A/Qwen/Qwen2.5-72B-Instruct
  - Qwen/Qwen2.5-7B-Instruct
  - Qwen2.5-72B-INT8
  - hunyuan-turbo
  - hunyuan-large


ui_available_workflow_datasets:
  # - "v241127"
  - "pdl_converted_20241221_4o"
ui_default_workflow_dataset: "pdl_converted_20241221_4o"

ui_bot_mode: ui_single_bot
ui_default_template: "bot_pdl_ui_zh.jinja"
ui_bot_template_fn: "flowagent/bot_pdl_ui_zh.jinja"
# ui_bot_mode: ui_single_fc_bot                         # NOTE: FC mode for open-source LLM is pretty bad!
# ui_default_template: "bot_pdl_ui_zh_fc.jinja"
# ui_bot_template_fn: "flowagent/bot_pdl_ui_zh_fc.jinja"
ui_available_models: *available_models
ui_available_templates:
  # - bot_pdl_ui.jinja
  - bot_pdl_ui_zh.jinja
  # - bot_pdl_ui_zh_fc.jinja
ui_default_model: "test-eason"          # default model for dev

ui_greeting_msg: "你好，我是{name}机器人，有什么可以帮您?"

api_entity_linking: false               # entity linking! FIXME: entity linker message not in log! (mismatch with client)

bot_pdl_controllers:
  - {name: "api_duplication", config: {if_pre: true, if_post: true, threshold: 2}, is_activated: true}
  - {name: "node_dependency", config: {if_pre: false, if_post: true}, is_activated: true}
  # - {name: "session_length", config: {if_pre: true, min: 5, max: 15}, is_activated: true}

db_uri: "mongodb://9.134.230.111:27017/"
db_name: "agent-pdl-dev"
db_collection_single: "dev_single_sessions"
db_collection_multi: "dev_multi_sessions"

backend_url: "http://localhost:8101"
